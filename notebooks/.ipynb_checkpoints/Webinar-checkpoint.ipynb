{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div sytle=\"align: center; text-align: center;\">\n",
    "  <center>\n",
    "  <img style=\"width:100px; margin: 10px !important;\" src=\"../img/logo-inferir.png\">\n",
    "  <h1 style=\"font-size: 50px; margin: 0 !important; align: center; font-weight: 900 !important; font-family: Courier New, monospace\">WEB SCRAPING</h1>\n",
    "  <h2 style=\"color: gray; margin: 0 !important\">Aprenda a coletar dados na internet de forma automatizada</h2>  \n",
    "    </center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# O que e Web Scraping?\n",
    "\n",
    "<div style=\"text-align: justify !important;\">\n",
    "    <center><img style=\"width: 50%; align: center;\" src=\"../img/scrap-web.png\"><br></center>\n",
    "<b>Web Scraping</b>, ou <b>Raspagem de Dados</b>, consiste em um processo que se utiliza de t√©cnicas de programa√ß√£o para a coleta automatizada de dados provenientes da Web.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Objetivo\n",
    "\n",
    "<div style=\"text-align: justify !important;\">\n",
    "O principal objetivo do Web Scraping √© extrair dados de servi√ßos ou aplicativos que n√£o oferecem uma interface de programa√ß√£o (API) e <b>TRANSFORMAR DADOS N√ÉO ESTRUTURADOS EM ESTRUTURADOS</b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img style=\"width: 40%\" src=\"../img/unstructured_data.png\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Scraper\n",
    "\n",
    "Scraper √© um software que simula a intera√ß√£o realizada entre um browser operado por um humano e um Web Site. Possui 3 fun√ß√µes b√°sicas:\n",
    "\n",
    "1. Acesso ao Web Site\n",
    "2. Parsing e Extra√ß√£o de conte√∫do\n",
    "3. Estrutura√ß√£o dos resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Procolo HTTP\n",
    "\n",
    "<div style=\"width: 100%; overflow: hidden;\">\n",
    "    <div style=\"width: 50%; float: left;\">\n",
    "        <center><h3>Requests</h3></center>\n",
    "        <img style=\"width: 100%;\" src=\"https://i0.wp.com/blogs.innovationm.com/wp-content/uploads/2016/10/HTTP-Protocol.png?fit=624%2C248\">\n",
    "    </div>\n",
    "    <div>\n",
    "        <center><h3>Headers</h3></center>\n",
    "        <img style=\"width: 50%;\" src=\"https://mdn.mozillademos.org/files/13687/HTTP_Request.png\">\n",
    "    </div>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Desenvolvendo um Scraper - 6 Etapas\n",
    "  <p></p>\n",
    "<div style=\"width: 100%; overflow: hidden; vertical-align:middle;\">\n",
    "    <div style=\"width: 50%; float: left;\">            \n",
    "    <ol>\n",
    "        <li>Identificar</li>\n",
    "        <li>Navegar</li>\n",
    "        <li>Replicar</li>\n",
    "        <li>Parsear</li>\n",
    "        <li>Validar</li>\n",
    "        <li>Iterar</li>\n",
    "        </ol>\n",
    "    </div>\n",
    "    <div>\n",
    "        <img style=\"width: 50%; vertical-align:middle;\" src=\"https://scrapingpros.com/wp-content/uploads/2017/01/scraper1-1.png\">\n",
    "    </div>\n",
    "</div>\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# 1. Identificar\n",
    "\n",
    "No primeiro passo do processo de desenvolvimento de um scraper precisamos entender qual √© a estrutura das p√°ginas que queremos raspar e tra√ßar um plano para extrair tudo que precisamos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# 2. Navegar\n",
    "\n",
    "Precisamos entender como localizar o dado que queremos\n",
    "extrair dentro do HTML da p√°gina. Esse passo pode ser\n",
    "extremamente simples, mas de vez em quando ele se tornar√° algo bastante complexo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Dev Tools\n",
    "\n",
    "O Dev Tools √© conjunto de ferramentas integradas ao browser construƒ±ÃÅdas para facilitar o desenvolvimento de Web Sites. Permite analisar o c√≥digo, o tr√°fego de rede e a performance de uma p√°gina. √â a principal ferramenta de apoio ao desenvolvimento de Scrapers.\n",
    "<center>\n",
    "<img style=\"width: 40%; float: left;\" src =\"https://cdn.pcsteps.com/wp-content/uploads/2015/09/Reset-Chrome-Reset-Firefox-to-Fix-Most-Problems.png\">\n",
    "<img style=\"width: 25%;\" src =\"https://cdn.instructables.com/FE1/3CR2/GV0KXNWV/FE13CR2GV0KXNWV.LARGE.jpg\">\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# 3. Replicar\n",
    "\n",
    "Neste passo √© importante compreender as v√°rias requisi√ß√µes HTTP\n",
    "que a p√°gina est√° realizando para trazer o conte√∫do at√© voc√™,\n",
    "assim poderemos replicar as requisi√ß√µes com nosso Scraper.\n",
    "Utilizaremos a aba Network do Dev Tools para este trabalho."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# 4. Parsear\n",
    "\n",
    "O anglicismo parsear vem do verbo to parse, que quer dizer algo como analisar ou estudar, mas que, no contexto do Web Scraping, significa extrair os dados desejados de um arquivo HTML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 5. Validar\n",
    "\n",
    "Se tivermos feito tudo certo at√© agora, validar os resultados ser√° uma tarefa simples. Precisamos apenas reproduzir o procedimento descrito at√© agora para algumas outras p√°ginas de modo verificar se estamos de fato extraindo corretamente tudo o que queremos.\n",
    "<center>\n",
    "<img style=\"width: 400px;\" src=\"https://cdn-images-1.medium.com/max/475/1*IbHgZrKYCUSeIbL_PywObQ.png\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 6. Iterar\n",
    "\n",
    "O √∫ltimo passo consiste em colocar o nosso scraper em produ√ß√£o. Aqui, ele j√° deve estar funcionando corretamente para todos os casos desejados. Na maior parte dos casos isso consiste em encapsular o scraper em uma fun√ß√£o que recebe uma s√©rie de links e aplica o mesmo procedimento em cada um. Se quisermos aumentar a efici√™ncia desse processo, podemos paralelizar ou distribuir o nosso raspador.\n",
    "\n",
    "<center>\n",
    "    <img style=\"width: 400px;\" src=\"https://www.freelancinggig.com/blog/wp-content/uploads/2017/02/google-aws-microsoft-azure.jpg\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "<h1> Power Trio do Web Scraping:</h1>\n",
    "    <h2>Requests</h2>\n",
    "    <h2>BeautifulSoup</h2>\n",
    "    <h2>Selenium</h2>\n",
    "<img style=\"width: 80%; padding: -100px\" src=\"../img/trio7.jpg\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Para instalar os pacotes:\n",
    "`pip install requests beautifulsoup selenium`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fun√ßoes acessorias\n",
    "import os\n",
    "import sys\n",
    "\n",
    "src = os.path.join(os.path.dirname(os.getcwd()))\n",
    "sys.path.append(src)\n",
    "\n",
    "from src import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download de Conte√∫do - Livros do Machado de Assis\n",
    "\n",
    "üîó http://machado.mec.gov.br/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dom_casmurro = 'http://machado.mec.gov.br/obra-completa-lista/item/download/13_7101e1a36cda79f6c97341757dcc4d04'\n",
    "response = requests.get(dom_casmurro)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisando a resposta HTTP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 200 OK \n",
      "\n",
      "Cabe√ßalho: {'Date': 'Wed, 21 Nov 2018 20:54:12 GMT', 'Server': 'Apache', 'X-Powered-By': 'PHP/5.4.16 ZendServer/6.1.0', 'Set-Cookie': 'ZDEDebuggerPresent=php,phtml,php3; path=/, 340406402bf808b75e1729e10d0d12ab=00mr5rhg3ogdgths6505q9046t76233v; path=/; HttpOnly', 'Pragma': 'public', 'Cache-Control': 'must-revalidate, post-check=0, pre-check=0', 'Content-Disposition': 'attachment; filename=domCasmurro.pdf;', 'Content-Transfer-Encoding': 'binary', 'Content-Length': '567017', 'Connection': 'close', 'Content-Type': 'application/pdf'} \n",
      "\n",
      "Tipo do Arquivo: application/pdf \n",
      "\n",
      "Tamanho do Arquivo: 567017\n"
     ]
    }
   ],
   "source": [
    "print('Status Code:', response.status_code, response.reason, '\\n')\n",
    "print('Cabe√ßalho:', response.headers, '\\n')\n",
    "print('Tipo do Arquivo:', response.headers['Content-Type'], '\\n')\n",
    "print('Tamanho do Arquivo:', response.headers['Content-Length'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvando o arquivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/dom_casmurro.pdf', 'wb') as f:\n",
    "    f.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 556\n",
      "-rw-r--r-- 1 rafael rafael 567017 nov 21 18:54 dom_casmurro.pdf\n"
     ]
    }
   ],
   "source": [
    "!ls -l ../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=../data/dom_casmurro.pdf width=800 height=500></iframe>"
      ],
      "text/latex": [
       "\\includegraphics[width=1.0\\textwidth]{../data/dom_casmurro.pdf}"
      ],
      "text/plain": [
       "<src.utils.PDF at 0x7ffb2f460ac8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.PDF('../data/dom_casmurro.pdf', size=(800,500))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enviando Dados\n",
    "\n",
    "* Fa√ßa login no site http://testing-ground.scraping.pro/login e inspecione as requisi√ßoes HTTP no Dev Tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GO BACK', 'GO BACK']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "session = requests.Session()\n",
    "url = 'http://testing-ground.scraping.pro/login?mode=login'\n",
    "data = {'pwd': '12345', 'usr': 'admin'}\n",
    "headers = {'User-Agent': ''}\n",
    "session.get('http://testing-ground.scraping.pro/login')\n",
    "response = session.post(url, data=data, headers=headers)\n",
    "re.findall('GO BACK', response.text) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BeautifulSoup\n",
    "\n",
    "## Introdu√ß√£o\n",
    "        \n",
    "<figure style=\"color:black;text-align:center\" name=\"alice-pais\">\n",
    "  <center>\n",
    "    <img src=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/_images/6.1.jpg\" align=\"middle\" class=\"ilustracao-livro\">            \n",
    "   <figcaption style=\"text-align: center;\">\n",
    "                Figura.1 - O nome BeautifulSoup √© inspirado no livro Alice no Pa√≠s das Maravilhas.\n",
    "   </figcaption>\n",
    "  </center>\n",
    "</figure>\n",
    "        <br>\n",
    "        <div id=\"content\">\n",
    "            BeautifulSoup √© um pacote para extra√ß√£o de dados de HTML e XML. A documenta√ß√£o pode ser encontrada neste\n",
    "            <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">link</a>.\n",
    "        </div>\n",
    "        <ul name=\"lista-caracteristicas\">\n",
    "            <li>Criado em 2004</li>\n",
    "            <li>Extra√ß√£o de dados em arquivos <b>XML</b> e <b>HTML</b></li>\n",
    "            <li>Funciona com diferentes parsers</li>\n",
    "            <li>Linguagem clara e intuitiva</li>\n",
    "            <li>Deteca√ß√£o e convers√£o autom√°tica da codifica√ß√£o das strings</li>\n",
    "            <li>√ìtima capacidade para lidar com c√≥digo HTML mal formatado</li>\n",
    "        </ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Campeoes Brasileiros [Wikipedia]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = 'https://en.wikipedia.org/wiki/Campeonato_Brasileiro_S%C3%A9rie_A'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "tables = soup.find_all('table')\n",
    "len(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Club</th>\n",
       "      <th>Won</th>\n",
       "      <th>Runner-up</th>\n",
       "      <th>Years won</th>\n",
       "      <th>Years Runner-up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Palmeiras</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>1960*, 1967*, 1967^, 1969^, 1972, 1973, 1993, ...</td>\n",
       "      <td>1970^, 1978, 1997, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Santos</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>1961*, 1962*, 1963*, 1964*, 1965*, 1968^, 2002...</td>\n",
       "      <td>1959*, 1966*, 1983, 1995, 2003, 2007, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Corinthians</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1990, 1998, 1999, 2005, 2011, 2015, 2017</td>\n",
       "      <td>1976, 1994, 2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S√£o Paulo</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1977, 1986, 1991, 2006, 2007, 2008</td>\n",
       "      <td>1971, 1973, 1981, 1989, 1990, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Flamengo</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1980, 1982, 1983, 1992, 2009</td>\n",
       "      <td>1964*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cruzeiro</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1966*, 2003, 2013, 2014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Club  Won  Runner-up  \\\n",
       "0    Palmeiras    9          4   \n",
       "1       Santos    8          7   \n",
       "2  Corinthians    7          3   \n",
       "3    S√£o Paulo    6          6   \n",
       "4     Flamengo    5          1   \n",
       "5     Cruzeiro    4          5   \n",
       "\n",
       "                                           Years won  \\\n",
       "0  1960*, 1967*, 1967^, 1969^, 1972, 1973, 1993, ...   \n",
       "1  1961*, 1962*, 1963*, 1964*, 1965*, 1968^, 2002...   \n",
       "2           1990, 1998, 1999, 2005, 2011, 2015, 2017   \n",
       "3                 1977, 1986, 1991, 2006, 2007, 2008   \n",
       "4                       1980, 1982, 1983, 1992, 2009   \n",
       "5                            1966*, 2003, 2013, 2014   \n",
       "\n",
       "                              Years Runner-up  \n",
       "0                     1970^, 1978, 1997, 2017  \n",
       "1  1959*, 1966*, 1983, 1995, 2003, 2007, 2016  \n",
       "2                            1976, 1994, 2002  \n",
       "3          1971, 1973, 1981, 1989, 1990, 2014  \n",
       "4                                       1964*  \n",
       "5                                         NaN  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabelas = pd.read_html(str(soup), header=0)\n",
    "len(tabelas)\n",
    "\n",
    "dados = tabelas[1]\n",
    "dados.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agenda Ministerial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "agenda_mp = 'http://www.fazenda.gov.br/acesso-a-informacao/institucional/agenda'\n",
    "response = requests.get(agenda_mp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"agenda-tile tile-content\" id=\"agenda-a82ddd9c-8cf5-4eb3-badc-688532e47816\">\n",
      " <h3 class=\"title\">\n",
      "  Ministro da Fazenda - Eduardo Refinetti Guardia\n",
      " </h3>\n",
      " <p class=\"period\">\n",
      "  <strong>\n",
      "   21 de novembro de 2018\n",
      "  </strong>\n",
      " </p>\n",
      " <div class=\"latest-update\">\n",
      "  <p>\n",
      "   Agenda atualizada\n",
      "  </p>\n",
      " </div>\n",
      " <ul class=\"collection-events\">\n",
      "  <li>\n",
      "   <div class=\"timestamp-cell\">\n",
      "    <span class=\"timestamp\">\n",
      "     09h30\n",
      "    </span>\n",
      "   </div>\n",
      "   <a class=\"title-item\" href=\"http://www.fazenda.gov.br/acesso-a-informacao/institucional/agenda/gabinete-do-ministro-da-fazenda/ministro-de-estado-da-fazenda/2018-11-21\">\n",
      "    Reuni√£o com o ministro do Planejamento, Esteves Colnago, e com o ministro da Educa√ß√£o, Rossieli Soares\n",
      "   </a>\n",
      "  </li>\n",
      "  <li>\n",
      "   <div class=\"timestamp-cell\">\n",
      "    <span class=\"timestamp\">\n",
      "     11h00\n",
      "    </span>\n",
      "   </div>\n",
      "   <a class=\"title-item\" href=\"http://www.fazenda.gov.br/acesso-a-informacao/institucional/agenda/gabinete-do-ministro-da-fazenda/ministro-de-estado-da-fazenda/2018-11-21\">\n",
      "    Junta de Execu√ß√£o Or√ßament√°ria (JEO)\n",
      "   </a>\n",
      "  </li>\n",
      "  <li>\n",
      "   <div class=\"timestamp-cell\">\n",
      "    <span class=\"timestamp\">\n",
      "     13h00\n",
      "    </span>\n",
      "   </div>\n",
      "   <a class=\"title-item\" href=\"http://www.fazenda.gov.br/acesso-a-informacao/institucional/agenda/gabinete-do-ministro-da-fazenda/ministro-de-estado-da-fazenda/2018-11-21\">\n",
      "    Almo√ßo com o general Fernando Azevedo e Silva\n",
      "   </a>\n",
      "  </li>\n",
      "  <li>\n",
      "   <div class=\"timestamp-cell\">\n",
      "    <span class=\"timestamp\">\n",
      "     14h00\n",
      "    </span>\n",
      "   </div>\n",
      "   <a class=\"title-item\" href=\"http://www.fazenda.gov.br/acesso-a-informacao/institucional/agenda/gabinete-do-ministro-da-fazenda/ministro-de-estado-da-fazenda/2018-11-21\">\n",
      "    Reuni√£o com o presidente da Petrobras, Ivan Monteiro\n",
      "   </a>\n",
      "  </li>\n",
      "  <li>\n",
      "   <div class=\"timestamp-cell\">\n",
      "    <span class=\"timestamp\">\n",
      "     14h30\n",
      "    </span>\n",
      "   </div>\n",
      "   <a class=\"title-item\" href=\"http://www.fazenda.gov.br/acesso-a-informacao/institucional/agenda/gabinete-do-ministro-da-fazenda/ministro-de-estado-da-fazenda/2018-11-21\">\n",
      "    Audi√™ncia com Jackson Schneider, Presidente Executivo de Neg√≥cio de Defesa e Seguran√ßa da Embraer\n",
      "   </a>\n",
      "  </li>\n",
      "  <li>\n",
      "   <div class=\"timestamp-cell\">\n",
      "    <span class=\"timestamp\">\n",
      "     15h00\n",
      "    </span>\n",
      "   </div>\n",
      "   <a class=\"title-item\" href=\"http://www.fazenda.gov.br/acesso-a-informacao/institucional/agenda/gabinete-do-ministro-da-fazenda/ministro-de-estado-da-fazenda/2018-11-21\">\n",
      "    Apresenta√ß√£o IBM - Tecnologia da Informa√ß√£o\n",
      "   </a>\n",
      "  </li>\n",
      " </ul>\n",
      " <div class=\"agenda-tile-footer\">\n",
      "  <a href=\"https://www.fazenda.gov.br/acesso-a-informacao/institucional/agenda/gabinete-do-ministro-da-fazenda/ministro-de-estado-da-fazenda\">\n",
      "   +detalhes\n",
      "  </a>\n",
      " </div>\n",
      "</div>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "agenda = soup.find('div', class_='agenda-tile tile-content')\n",
    "print(agenda.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('09h30',\n",
       "  'Reuni√£o com o ministro do Planejamento, Esteves Colnago, e com o ministro da Educa√ß√£o, Rossieli Soares'),\n",
       " ('11h00', 'Junta de Execu√ß√£o Or√ßament√°ria (JEO)'),\n",
       " ('13h00', 'Almo√ßo com o general Fernando Azevedo e Silva'),\n",
       " ('14h00', 'Reuni√£o com o presidente da Petrobras, Ivan Monteiro'),\n",
       " ('14h30',\n",
       "  'Audi√™ncia com Jackson Schneider, Presidente Executivo de Neg√≥cio de Defesa e Seguran√ßa da Embraer'),\n",
       " ('15h00', 'Apresenta√ß√£o IBM - Tecnologia da Informa√ß√£o')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_agenda = []\n",
    "eventos = agenda.find_all('li')\n",
    "for evento in eventos:\n",
    "    horario = evento.find('span').text\n",
    "    descricao = evento.find('a').text\n",
    "    dados_agenda.append((horario, descricao))\n",
    "dados_agenda"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:web]",
   "language": "python",
   "name": "conda-env-web-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
